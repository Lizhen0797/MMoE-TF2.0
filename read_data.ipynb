{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    返回census-income数据集\n",
    "    @param train_data:训练集特征\n",
    "    @param train_label:训练集标签\n",
    "    @param test_data:测试集特征\n",
    "    @param test_label:测试集标签\n",
    "    @param validation_data:验证集特征\n",
    "    @param validation_label:验证集标签\n",
    "'''\n",
    "def data_processing():\n",
    "    # 数据集列表名\n",
    "    column_names = ['age', 'class_worker', 'det_ind_code', 'det_occ_code', 'education', 'wage_per_hour', 'hs_college',\n",
    "                    'marital_stat', 'major_ind_code', 'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member',\n",
    "                    'unemp_reason', 'full_or_part_emp', 'capital_gains', 'capital_losses', 'stock_dividends',\n",
    "                    'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat', 'det_hh_summ',\n",
    "                    'instance_weight', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                    'num_emp', 'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                    'own_or_self', 'vet_question', 'vet_benefits', 'weeks_worked', 'year', 'income_50k']\n",
    "    #读取训练数据\n",
    "    train_df = pd.read_csv(\n",
    "        '/Users/lizhen/Code/data_set/census-income/census-income.data.gz',\n",
    "        delimiter=',',\n",
    "        header=None,\n",
    "        index_col=None,\n",
    "        names=column_names\n",
    "    )\n",
    "    #读取测试数据\n",
    "    other_df = pd.read_csv(\n",
    "        '/Users/lizhen/Code/data_set/census-income/census-income.test.gz',\n",
    "        delimiter=',',\n",
    "        header=None,\n",
    "        index_col=None,\n",
    "        names=column_names\n",
    "    )\n",
    "    # 特征名字\n",
    "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
    "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
    "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
    "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                           'vet_question']\n",
    "    # First group of tasks according to the paper\n",
    "    label_columns = ['income_50k', 'marital_stat']\n",
    "\n",
    "    # One-hot encoding categorical columns\n",
    "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
    "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
    "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
    "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                           'vet_question']\n",
    "    train_raw_labels = train_df[label_columns]\n",
    "    other_raw_labels = other_df[label_columns]\n",
    "    transformed_train = pd.get_dummies(train_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
    "    transformed_other = pd.get_dummies(other_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
    "    #print(transformed_train.columns.values)\n",
    "    #print(transformed_other.shape)\n",
    "    #print(transformed_train.shape)\n",
    "    \n",
    "    transformed_other['det_hh_fam_stat_ Grandchild <18 ever marr not in subfamily'] = 0\n",
    "    \n",
    "    #获得标签量，并根据要求转换为one-hot向量\n",
    "    train_income = keras.utils.to_categorical((train_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
    "    train_marital = keras.utils.to_categorical((train_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
    "    other_income = keras.utils.to_categorical((other_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
    "    other_marital = keras.utils.to_categorical((other_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
    "    \n",
    "    # 转换为字典\n",
    "    dict_outputs = {\n",
    "        'income': train_income.shape[1],\n",
    "        'marital': train_marital.shape[1]\n",
    "    }\n",
    "    dict_train_labels = {\n",
    "        'income': train_income,\n",
    "        'marital': train_marital\n",
    "    }\n",
    "    dict_other_labels = {\n",
    "        'income': other_income,\n",
    "        'marital': other_marital\n",
    "    }\n",
    "    output_info = [(dict_outputs[key], key) for key in sorted(dict_outputs.keys())]\n",
    "    \n",
    "    # 将测试集划分 为测试集和验证集 1:1的比例\n",
    "    validation_indices = transformed_other.sample(frac=0.5, replace=False, random_state=1).index\n",
    "    test_indices = list(set(transformed_other.index) - set(validation_indices))\n",
    "    validation_data = transformed_other.iloc[validation_indices]\n",
    "    validation_label = [dict_other_labels[key][validation_indices] for key in sorted(dict_other_labels.keys())]\n",
    "    test_data = transformed_other.iloc[test_indices]\n",
    "    test_label = [dict_other_labels[key][test_indices] for key in sorted(dict_other_labels.keys())]\n",
    "    train_data = transformed_train\n",
    "    train_label = [dict_train_labels[key] for key in sorted(dict_train_labels.keys())]\n",
    "\n",
    "    return train_data, train_label, validation_data, validation_label, test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    生成包含数据及标签的矩阵,因为在这里label是一个包含两个array的矩阵，因此需要有部分操作\n",
    "    @param data 数据集合\n",
    "    @param label 数据标签\n",
    "    \n",
    "    @return data 返回数据与数据集合一起的标签\n",
    "'''\n",
    "def generate_data(data, label):\n",
    "    for i in range(0, len(label)):\n",
    "        data = np.c_[data, label[i]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label, val_data, val_label, test_data, test_label = data_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_np = generate_data(train_data, train_label)\n",
    "test_data_np = generate_data(test_data, test_label)\n",
    "val_data_np = generate_data(val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/Users/lizhen/Code/data_set/census-income/generate_csv'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    @param output_dir 输出目录\n",
    "    @param data 输出数据\n",
    "    @param name_prefix 文件名前缀\n",
    "    @param header\n",
    "    @param n_parts 划分文件数大小\n",
    "    @return filenames 生成文件名list\n",
    "'''\n",
    "def save_to_csv(output_dir, data, name_prefix, header=None, n_parts=10):\n",
    "    path_format = os.path.join(output_dir, '{}_{:02d}.csv')\n",
    "    filenames = []\n",
    "    \n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(len(data)), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filenames.append(part_csv)\n",
    "        with open(part_csv, 'wt', encoding='utf-8') as f:\n",
    "            if header is not None:\n",
    "                f.write(header + '\\n')\n",
    "            for row_index in row_indices:\n",
    "                f.write(','.join([repr(col) for col in data[row_index]]))\n",
    "                f.write('\\n')\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_00.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_01.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_02.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_03.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_04.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_05.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_06.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_07.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_08.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_09.csv']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_to_csv(output_dir, train_data_np, 'train_data', None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_00.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_01.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_02.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_03.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_04.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_05.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_06.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_07.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_08.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_09.csv']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_to_csv(output_dir, test_data_np, 'test_data', None, 10)\n",
    "save_to_csv(output_dir, val_data_np, 'val_data', None,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    将csv数据每一行转换为特征值和标签值\n",
    "    @param line line\n",
    "    @param n_feature 特征纬度\n",
    "    @return x 特征\n",
    "    @return y 标签\n",
    "'''\n",
    "def parse_csv_line(line, n_feature=503):\n",
    "    defs = [tf.constant(np.nan)] * n_feature\n",
    "    parsed_field = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(parsed_field[0:-4])\n",
    "    y_income = tf.stack(parsed_field[-4:-2])\n",
    "    y_marital = tf.stack(parsed_field[-2:])\n",
    "    return x, (y_income, y_marital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    将csv文件列表处理为TFDataSet\n",
    "    @param filenames csv文件名列表\n",
    "    @param n_reader interleave cycle_length\n",
    "    @param batch_size batch_size\n",
    "    @param n_parse_threads map的并行数\n",
    "    @param shuffle_buffer_size shuffer_size\n",
    "    @return dataset TFDataset\n",
    "'''\n",
    "def csv_reader_dataset(filenames, n_readers=5, batch_size=32, n_parse_threads=5, shuffle_buffer_size=10000):\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filename : tf.data.TextLineDataset(filename),\n",
    "        cycle_length=n_readers\n",
    "    )\n",
    "    dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(parse_csv_line, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = csv_reader_dataset(['/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_00.csv',\n",
    " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_01.csv',\n",
    " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_02.csv',\n",
    " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_03.csv',\n",
    " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_04.csv',\n",
    " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_05.csv',\n",
    " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_06.csv',\n",
    " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_07.csv',\n",
    " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_08.csv',\n",
    " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_09.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    通过前缀获取文件列表\n",
    "    @param source_dir 源文件目录\n",
    "    @param prefix_name 前缀名\n",
    "    @return result list\n",
    "'''\n",
    "def get_filename_by_prefix(source_dir,prefix_name):\n",
    "    all_files = os.listdir(source_dir)\n",
    "    results = []\n",
    "    for filename in all_files:\n",
    "        if filename.startswith(prefix_name):\n",
    "            results.append(os.path.join(source_dir, filename))\n",
    "    return results\n",
    "source_dir='/Users/lizhen/Code/data_set/census-income/generate_csv/'\n",
    "train_filenames = get_filename_by_prefix(source_dir, 'train')\n",
    "valid_filenames = get_filename_by_prefix(source_dir, 'val')\n",
    "test_filenames = get_filename_by_prefix(source_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_00.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_01.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_03.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_02.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_06.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_07.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_05.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_04.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_09.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/train_data_08.csv']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    将数据serialize\n",
    "    @param x feature\n",
    "    @param y label\n",
    "    @return serialize data\n",
    "'''\n",
    "def serialize(x, y):\n",
    "    input_features = tf.train.FloatList(value=x)\n",
    "    income_label = tf.train.Int64List(value=y[0:2])\n",
    "    marital_label = tf.train.Int64List(value=y[2:])\n",
    "    features = tf.train.Features(\n",
    "        feature={\n",
    "            'features':tf.train.Feature(float_list=input_features),\n",
    "            'income_label':tf.train.Feature(int64_list=income_label),\n",
    "            'marital_label':tf.train.Feature(int64_list=marital_label)\n",
    "        }\n",
    "    )\n",
    "    example = tf.train.Example(features=features)\n",
    "    return example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    将csv数据转换为tfrecords数据\n",
    "'''\n",
    "def csv_dataset_to_tfrecords(base_filename, dataset, n_shards, step_per_shard, compression_type=None):\n",
    "    options = tf.io.TFRecordOptions(compression_type=compression_type)\n",
    "    filenames = []\n",
    "    for shard_id in range(n_shards):\n",
    "        filename_fullpath = '{}-{:05d}-of{:05d}'.format(base_filename, shard_id, n_shards)\n",
    "        with tf.io.TFRecordWriter(filename_fullpath, options) as writer:\n",
    "            for x_batch, y_batch in dataset.take(step_per_shard):\n",
    "                for x_example, y_example in zip(x_batch, y_batch):\n",
    "                    writer.write(serialize(x_example, y_example))\n",
    "        filenames.append(filename_fullpath)\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shards = 10\n",
    "train_step_per_shard = train_data_np.shape[0] // 32//n_shards\n",
    "test_step_per_shard = test_data_np.shape[0] // 32//n_shards\n",
    "val_step_per_shard = val_data_np.shape[0] // 32//n_shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "623"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step_per_shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_step_per_shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_step_per_shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/Users/lizhen/Code/data_set/census-income/generate_tfrecords'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "train_basename = os.path.join(output_dir,'train')\n",
    "test_basename = os.path.join(output_dir,'test')\n",
    "val_basename = os.path.join(output_dir,'val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_03.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_02.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_00.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_01.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_05.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_04.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_06.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_07.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_09.csv',\n",
       " '/Users/lizhen/Code/data_set/census-income/generate_csv/val_data_08.csv']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = csv_reader_dataset(train_filenames)\n",
    "test_dataset = csv_reader_dataset(test_filenames)\n",
    "val_dataset = csv_reader_dataset(valid_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dataset_to_tfrecords(train_basename, train_dataset, n_shards, train_step_per_shard,\"GZIP\")\n",
    "csv_dataset_to_tfrecords(test_basename, test_dataset, n_shards, test_step_per_shard,\"GZIP\")\n",
    "csv_dataset_to_tfrecords(val_basename, val_dataset, n_shards, val_step_per_shard,\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
